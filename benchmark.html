<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>oobabooga benchmark</title>

  <style>
    :root {
      --primary-color: #3498db;
      --secondary-color: #2c3e50;
      --background-color: #f4f4f4;
      --text-color: #333;
    }

    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: var(--background-color);
      color: var(--text-color);
      line-height: 1.6;
    }

    .container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
    }

    .title {
      text-align: center;
      color: var(--secondary-color);
      font-size: 32px;
      margin-bottom: 20px;
    }

    table {
      width: 100%;
      border-collapse: separate;
      border-spacing: 0;
      background-color: #fff;
      box-shadow: 0 1px 3px rgba(0, 0, 0, 0.12), 0 1px 2px rgba(0, 0, 0, 0.24);
      border-radius: 8px;
      overflow: hidden;
    }

    th,
    td {
      padding: 15px;
      text-align: left;
      border-bottom: 1px solid #e0e0e0;
    }

    td {
      padding: 5px 15px;
    }

    th {
      background-color: var(--primary-color);
      color: #fff;
      font-weight: bold;
      text-transform: uppercase;
    }

    tbody tr:hover {
      background-color: #f5f5f5;
    }

    .comments {
      margin-top: 30px;
      padding: 20px;
      background-color: #fff;
      border-radius: 8px;
      box-shadow: 0 1px 3px rgba(0, 0, 0, 0.12), 0 1px 2px rgba(0, 0, 0, 0.24);
    }

    .support {
      text-align: center;
      margin-top: 30px;
      font-size: 18px;
    }

    a {
      color: var(--primary-color);
      text-decoration: none;
      transition: color 0.3s ease;
    }

    a:hover {
      color: var(--secondary-color);
    }

    input[type="text"] {
      width: 100%;
      padding: 10px;
      border: 1px solid #ddd;
      border-radius: 4px;
      box-sizing: border-box;
    }

    @media screen and (max-width: 768px) {
      .container {
        padding: 10px;
      }

      table {
        font-size: 14px;
      }

      th,
      td {
        padding: 10px;
      }
    }
  </style>
</head>

<body>
  <div class="container">
    <h1 class="title">oobabooga benchmark</h1>
    <div style="text-align: center; margin-bottom: 36px">
      <p>The list is sorted alphabetically for each score.</p>
    </div>
    <table>
      <thead>
        <tr>
          <th>Score</th>
          <th>Model</th>
          <th>Size</th>
          <th>Loader</th>
          <th>Additional info</th>
        </tr>
      </thead>
      <tbody>
        <tr><td>34/48</td><td>LoneStriker_OpenBioLLM-Llama3-70B-6.0bpw-h6-exl2</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>34/48</td><td>Meta-Llama-3-70B-Instruct-Q4_K_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>34/48</td><td>platypus-yi-34b.Q8_0</td><td>34B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>33/48</td><td>01-ai_Yi-1.5-34B-Chat</td><td>34B</td><td>Transformers</td><td>--load-in-8bit</td></tr>
<tr><td>33/48</td><td>01-ai_Yi-1.5-34B-Chat-16K</td><td>34B</td><td>Transformers</td><td>--load-in-8bit</td></tr>
<tr><td>33/48</td><td>dolphin-2.9.3-Yi-1.5-34B-32k-Q8_0</td><td>34B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/dolphin-2.9.3-Yi-1.5-34B-32k-GGUF">[link]</a></td></tr>
<tr><td>33/48</td><td>gemma-2-27b-it-Q8_0_L</td><td>27B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/gemma-2-27b-it-GGUF">[link]</a></td></tr>
<tr><td>33/48</td><td>google_gemma-2-27b-it</td><td>27B</td><td>Transformers</td><td>--bf16 --use_eager_attention</td></tr>
<tr><td>33/48</td><td>ISTA-DASLab_Meta-Llama-3-70B-Instruct-AQLM-2Bit-1x16</td><td>70B</td><td>Transformers</td><td></td></tr>
<tr><td>33/48</td><td>Llama3-TenyxChat-70B.i1-Q4_K_S</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>33/48</td><td>LoneStriker_dolphin-2.9-llama3-70b-6.0bpw-h6-exl2</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>33/48</td><td>magnum-72b-v1-Q4_K_M</td><td>72B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/magnum-72b-v1-GGUF">[link]</a></td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct-IQ3_XS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct-IQ3_XXS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct-Q3_K_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct.Q8_0</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>33/48</td><td>Smaug-Llama-3-70B-Instruct.i1-Q4_K_S</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>33/48</td><td>turboderp_Cat-Llama-3-70B-instruct-exl2_5.0bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>33/48</td><td>turboderp_Llama-3-70B-Instruct-exl2_5.0bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>33/48</td><td>turboderp_Llama-3-70B-Instruct-exl2_6.0bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>33/48</td><td>Undi95_Meta-Llama-3-70B-Instruct-hf</td><td>70B</td><td>Transformers</td><td>--load-in-4bit</td></tr>
<tr><td>32/48</td><td>Llama-3-Giraffe-70B-Instruct.i1-Q4_K_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/mradermacher/Llama-3-Giraffe-70B-Instruct-i1-GGUF/tree/main">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_M</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ3_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ4_NL</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ4_XS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-Q3_K_L</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-Q3_K_M</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Qwen2-72B-Instruct-Q4_K_M</td><td>72B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Qwen2-72B-Instruct-GGUF">[link]</a></td></tr>
<tr><td>32/48</td><td>turboderp_gemma-2-27b-it-exl2_8.0bpw</td><td>27B</td><td>ExLlamav2_HF</td><td>--no_flash_attn --no_xformers --no_sdpa</td></tr>
<tr><td>31/48</td><td>cloudyu_Phoenix_DPO_60B</td><td>60B</td><td>Transformers</td><td>--load-in-8bit</td></tr>
<tr><td>31/48</td><td>Meta-Llama-3-120B-Instruct.Q4_K_M</td><td>120B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3-120B-Instruct-GGUF/tree/main">[link]</a></td></tr>
<tr><td>31/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_XS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/blob/main/Meta-Llama-3-70B-Instruct-IQ2_XS.gguf">[link]</a></td></tr>
<tr><td>31/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_XS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>31/48</td><td>Meta-Llama-3-70B-Instruct-IQ3_M</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>31/48</td><td>Meta-Llama-3-70B-Instruct-Q2_K</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>31/48</td><td>microsoft_Phi-3-medium-128k-instruct</td><td>14B</td><td>Transformers</td><td></td></tr>
<tr><td>31/48</td><td>miqu-1-70b.q4_k_m</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>31/48</td><td>miqu-1-70b.q5_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>31/48</td><td>oobabooga_miqu-1-70b-sf-EXL2-6.000b</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>30/48</td><td>Dracones_WizardLM-2-8x22B_exl2_4.0bpw</td><td>8x22B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>30/48</td><td>falcon-180b-chat.Q4_K_M</td><td>180B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>30/48</td><td>google_gemma-2-27b-it</td><td>27B</td><td>Transformers</td><td>--load-in-4bit --bf16 --use_eager_attention</td></tr>
<tr><td>30/48</td><td>Llama3-70B-ShiningValiant2.i1-Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/mradermacher/Llama3-70B-ShiningValiant2-i1-GGUF">[link]</a></td></tr>
<tr><td>30/48</td><td>Meta-Llama-3-70B-Instruct-abliterated-v3.5.i1-Q4_K_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/mradermacher/Meta-Llama-3-70B-Instruct-abliterated-v3.5-i1-GGUF">[link]</a></td></tr>
<tr><td>30/48</td><td>miquliz-120b-v2.0.Q4_K_M</td><td>120B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>30/48</td><td>qwen1_5-72b-chat-q4_k_m</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>30/48</td><td>Rhea-72b-v0.5-Q4_K_M</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>30/48</td><td>Senku-70B-Full-Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>30/48</td><td>turboderp_Mixtral-8x22B-Instruct-v0.1-exl2_4.0bpw</td><td>8x22B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>29/48</td><td>34b-beta.Q8_0</td><td>34B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>29/48</td><td>bartowski_Qwen1.5-32B-Chat-exl2_5_0</td><td>32B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>29/48</td><td>c4ai-command-r-plus.i1-IQ4_XS</td><td>104B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/mradermacher/c4ai-command-r-plus-i1-GGUF">[link]</a></td></tr>
<tr><td>29/48</td><td>daybreak-miqu-1-70b-v1.0-q5_k_m</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>29/48</td><td>Dracones_Llama-3-Lumimaid-70B-v0.1_exl2_4.5bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>29/48</td><td>google_gemma-2-9b-it</td><td>9B</td><td>Transformers</td><td>--bf16 --use_eager_attention</td></tr>
<tr><td>29/48</td><td>Llama3-ChatQA-1.5-70B.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td>Alpaca template.</td></tr>
<tr><td>29/48</td><td>LoneStriker_Yi-34B-Chat-8.0bpw-h8-exl2</td><td>34B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>29/48</td><td>microsoft_Phi-3-medium-4k-instruct</td><td>14B</td><td>Transformers</td><td></td></tr>
<tr><td>29/48</td><td>Qwen1.5-110B-Chat-Q4_K_M</td><td>110B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/LoneStriker/Qwen1.5-110B-Chat-GGUF/">[link]</a></td></tr>
<tr><td>29/48</td><td>turboderp_command-r-plus-103B-exl2_3.0bpw</td><td>104B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>29/48</td><td>turboderp_Llama-3-70B-exl2_5.0bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>29/48</td><td>UCLA-AGI_Gemma-2-9B-It-SPPO-Iter3</td><td>9B</td><td>Transformers</td><td>--bf16 --use_eager_attention</td></tr>
<tr><td>28/48</td><td>command-r-plus-Q4_K_M</td><td>104B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>28/48</td><td>dolphin-2.7-mixtral-8x7b.Q8_0</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>28/48</td><td>gemma-2-9b-it-Q8_0_L</td><td>9B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/gemma-2-9b-it-GGUF">[link]</a></td></tr>
<tr><td>28/48</td><td>LoneStriker_Smaug-72B-v0.1-6.0bpw-h6-exl2</td><td>72B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>28/48</td><td>turboderp_command-r-plus-103B-exl2_3.5bpw</td><td>104B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>28/48</td><td>turboderp_command-r-plus-103B-exl2_4.5bpw</td><td>104B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>27/48</td><td>01-ai_Yi-1.5-9B-Chat</td><td>9B</td><td>Transformers</td><td></td></tr>
<tr><td>27/48</td><td>google_gemma-2-9b-it</td><td>9B</td><td>Transformers</td><td>--load-in-8bit --bf16 --use_eager_attention</td></tr>
<tr><td>27/48</td><td>ISTA-DASLab_c4ai-command-r-plus-AQLM-2Bit-1x16</td><td>104B</td><td>Transformers</td><td></td></tr>
<tr><td>27/48</td><td>Llama3-ChatQA-1.5-70B.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td>NVIDIA-ChatQA template.</td></tr>
<tr><td>27/48</td><td>Midnight-Miqu-70B-v1.0.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>27/48</td><td>miqu-1-70b.q2_K</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>27/48</td><td>mixtral-8x7b-instruct-v0.1.Q8_0</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>27/48</td><td>Platypus2-70B.i1-Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/mradermacher/Platypus2-70B-i1-GGUF">[link]</a></td></tr>
<tr><td>27/48</td><td>Qwen_Qwen2-7B-Instruct</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>27/48</td><td>TheBloke_Helion-4x34B-GPTQ</td><td>4x34B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>26/48</td><td>CausalLM-RP-34B.q8_0</td><td>34B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>26/48</td><td>google_gemma-2-9b-it</td><td>9B</td><td>Transformers</td><td>--load-in-4bit --bf16 --use_eager_attention</td></tr>
<tr><td>26/48</td><td>internlm_internlm2_5-7b-chat</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>26/48</td><td>LoneStriker_dolphin-2.2-yi-34b-200k-8.0bpw-h8-exl2</td><td>34B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>26/48</td><td>LoneStriker_Yi-34B-200K-8.0bpw-h8-exl2</td><td>34B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>26/48</td><td>lzlv_70b_fp16_hf.Q5_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>26/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_XXS</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>26/48</td><td>microsoft_Phi-3-small-8k-instruct</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>26/48</td><td>Mixtral-8x22B-Instruct-v0.1.Q4_K_M</td><td>8x22B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>26/48</td><td>nous-hermes-2-mixtral-8x7b-dpo.Q8_0</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>26/48</td><td>Qwen_Qwen1.5-14B-Chat</td><td>14B</td><td>Transformers</td><td></td></tr>
<tr><td>26/48</td><td>turboderp_gemma-2-27b-it-exl2_3.0bpw</td><td>27B</td><td>ExLlamav2_HF</td><td>--no_flash_attn --no_xformers --no_sdpa</td></tr>
<tr><td>25/48</td><td>goliath-120b.Q4_K_M</td><td>120B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>25/48</td><td>LoneStriker_Llama-3-70B-Instruct-Gradient-524k-6.0bpw-h6-exl2</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>25/48</td><td>NousResearch_Nous-Hermes-2-SOLAR-10.7B</td><td>10.7B</td><td>Transformers</td><td></td></tr>
<tr><td>25/48</td><td>turboderp_Llama-3-70B-Instruct-exl2_2.4bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>24/48</td><td>LoneStriker_Llama-3-70B-Instruct-Gradient-262k-6.0bpw-h6-exl2</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>24/48</td><td>maid-yuzu-v8-alter.Q8_0</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>24/48</td><td>MultiVerse_70B.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>24/48</td><td>upstage_SOLAR-10.7B-Instruct-v1.0</td><td>10.7B</td><td>Transformers</td><td></td></tr>
<tr><td>23/48</td><td>bhenrym14_airoboros-3_1-yi-34b-200k</td><td>34B</td><td>Transformers</td><td>--load-in-8bit</td></tr>
<tr><td>23/48</td><td>microsoft_Phi-3-mini-4k-instruct</td><td>3.8B</td><td>Transformers</td><td></td></tr>
<tr><td>23/48</td><td>xwin-lm-70b-v0.1.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>22/48</td><td>liuhaotian_llava-v1.5-13b</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>22/48</td><td>meraGPT_mera-mix-4x7B</td><td>4x7B</td><td>Transformers</td><td></td></tr>
<tr><td>22/48</td><td>Meta-Llama-3-8B-Instruct-Q4_K_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>22/48</td><td>MoMo-72B-lora-1.8.6-DPO-Q4_K_M</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>22/48</td><td>Qwen_Qwen1.5-7B-Chat</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>22/48</td><td>tulu-2-dpo-70b.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>22/48</td><td>turboderp_command-r-plus-103B-exl2_2.5bpw</td><td>104B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>22/48</td><td>turboderp_command-r-v01-35B-exl2_6.0bpw</td><td>35B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>22/48</td><td>wizardlm-70b-v1.0.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>21/48</td><td>01-ai_Yi-1.5-6B-Chat</td><td>6B</td><td>Transformers</td><td></td></tr>
<tr><td>21/48</td><td>c4ai-command-r-v01-Q8_0</td><td>35B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>21/48</td><td>falcon-180b.Q4_K_M</td><td>180B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>21/48</td><td>gustavecortal_oneirogen-7B</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>21/48</td><td>internlm_internlm2-chat-20b</td><td>20B</td><td>Transformers</td><td></td></tr>
<tr><td>21/48</td><td>Meta-Llama-3-8B-Instruct-fp16</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>21/48</td><td>Meta-Llama-3-8B-Instruct-Q8_0</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>21/48</td><td>microsoft_Phi-3-small-128k-instruct</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>21/48</td><td>microsoft_Phi-3-vision-128k-instruct</td><td>4.2B</td><td>Transformers</td><td></td></tr>
<tr><td>21/48</td><td>NurtureAI_Meta-Llama-3-8B-Instruct-64k</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>21/48</td><td>Salesforce_SFR-Iterative-DPO-LLaMA-3-8B-R</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>21/48</td><td>Undi95_Meta-Llama-3-8B-Instruct-hf</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>20/48</td><td>BAAI_Bunny-Llama-3-8B-V</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>20/48</td><td>CohereForAI_aya-23-35B</td><td>35B</td><td>Transformers</td><td>--load-in-8bit</td></tr>
<tr><td>20/48</td><td>Ein-72B-v0.1-full.Q4_K_M</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>20/48</td><td>llama-2-70b-chat.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>20/48</td><td>Meta-Llama-3-8B-Instruct-Q6_K</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>20/48</td><td>microsoft_Phi-3-mini-4k-instruct-20240701</td><td>3.8B</td><td>Transformers</td><td></td></tr>
<tr><td>20/48</td><td>openchat_openchat_3.5</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>20/48</td><td>TheBloke_llava-v1.5-13B-GPTQ</td><td>13B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>20/48</td><td>Weyaxi_Einstein-v6.1-Llama3-8B</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>ai21labs_Jamba-v0.1</td><td>52B</td><td>Transformers</td><td>--load-in-4bit</td></tr>
<tr><td>19/48</td><td>internlm_internlm2-chat-20b-sft</td><td>20B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>internlm_internlm2-chat-7b</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>lightblue_suzume-llama-3-8B-multilingual</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>llama-2-70b.Q5_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-IQ3_S</td><td>8B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/blob/main/Meta-Llama-3-8B-Instruct-IQ3_S.gguf">[link]</a></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-IQ4_NL</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-IQ4_XS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-Q4_K_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-Q5_K_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-Q5_K_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>microsoft_Phi-3-mini-128k-instruct</td><td>3.8B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>mistral-7b-instruct-v0.2.Q4_K_S</td><td>7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Nexusflow_Starling-LM-7B-beta</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>NousResearch_Hermes-2-Pro-Mistral-7B</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>UCLA-AGI_Llama-3-Instruct-8B-SPPO-Iter3</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>zephyr-orpo-141b-A35b-v0.1.Q4_K_M</td><td>141B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>18/48</td><td>failspy_kappa-3-phi-abliterated</td><td>3.8B</td><td>Transformers</td><td></td></tr>
<tr><td>18/48</td><td>jieliu_Storm-7B</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>18/48</td><td>LoneStriker_Nous-Capybara-34B-4.65bpw-h6-exl2</td><td>34B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>18/48</td><td>Meta-Llama-3-70B-Instruct-IQ1_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>18/48</td><td>Meta-Llama-3-8B-Instruct-Q3_K_L</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>18/48</td><td>Meta-Llama-3-8B-Instruct-Q3_K_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>18/48</td><td>microsoft_Phi-3-mini-128k-instruct</td><td>3.8B</td><td>Transformers</td><td>--load-in-8bit</td></tr>
<tr><td>18/48</td><td>mistralai_Mistral-7B-Instruct-v0.2</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>18/48</td><td>Orenguteng_Lexi-Llama-3-8B-Uncensored</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>18/48</td><td>Qwen_Qwen1.5-MoE-A2.7B-Chat</td><td>14.3B</td><td>Transformers</td><td></td></tr>
<tr><td>18/48</td><td>TheProfessor-155b.i1-IQ3_XS</td><td>155B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/mradermacher/TheProfessor-155b-i1-GGUF/tree/main">[link]</a></td></tr>
<tr><td>18/48</td><td>turboderp_llama3-turbcat-instruct-8b</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>17/48</td><td>amazingvince_Not-WizardLM-2-7B</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>17/48</td><td>ggml-alpaca-dragon-72b-v1-q4_k_m</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>17/48</td><td>grok-1-IQ2_XS</td><td>314B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/Arki05/Grok-1-GGUF/tree/main/IQ2_XS">[link]</a></td></tr>
<tr><td>17/48</td><td>internlm_internlm2-chat-7b-sft</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>17/48</td><td>kubernetes-bad_Mistral-7B-Instruct-v0.3</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>17/48</td><td>microsoft_Phi-3-mini-128k-instruct</td><td>3.8B</td><td>Transformers</td><td>--load-in-4bit</td></tr>
<tr><td>17/48</td><td>mzbac_llama-3-8B-Instruct-function-calling</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>17/48</td><td>openchat_openchat-3.6-8b-20240522</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>17/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_5.0bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>17/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_6.0bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>17/48</td><td>Undi95_Toppy-M-7B</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>17/48</td><td>ZeusLabs_L3-Aethora-15B-V2</td><td>15B</td><td>Transformers</td><td></td></tr>
<tr><td>16/48</td><td>Meta-Llama-3-8B-Instruct-IQ3_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>16/48</td><td>microsoft_Phi-3-mini-128k-instruct-20240701</td><td>3.8B</td><td>Transformers</td><td></td></tr>
<tr><td>16/48</td><td>mixtral-8x7b-instruct-v0.1.Q2_K</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q4_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q4_K_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q4_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q5_0</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q6_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>16/48</td><td>TheBloke_Mistral-7B-Instruct-v0.2-GPTQ</td><td>7B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>15/48</td><td>cognitivecomputations_dolphin-2.9-llama3-8b</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>15/48</td><td>CohereForAI_c4ai-command-r-v01-4bit</td><td>35B</td><td>Transformers</td><td></td></tr>
<tr><td>15/48</td><td>hjhj3168_Llama-3-8b-Orthogonalized-exl2</td><td>8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>15/48</td><td>Meta-Llama-3-8B-Instruct-IQ3_XS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>15/48</td><td>NousResearch_Hermes-2-Pro-Llama-3-8B</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>15/48</td><td>Phi-3-mini-128k-instruct-IQ4_NL</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>15/48</td><td>Phi-3-mini-128k-instruct-IQ4_XS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>15/48</td><td>Phi-3-mini-128k-instruct-Q4_0</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>15/48</td><td>Phi-3-mini-128k-instruct-Q5_0</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>15/48</td><td>xtuner_llava-llama-3-8b-v1_1</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>14/48</td><td>Gryphe_MythoMax-L2-13b</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>14/48</td><td>mattshumer_Llama-3-8B-16K</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>14/48</td><td>Meta-Llama-3-8B-Instruct-IQ3_XXS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>14/48</td><td>Meta-Llama-3-8B-Instruct-Q3_K_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>14/48</td><td>microsoft_Orca-2-13b</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>14/48</td><td>nvidia_ChatQA-1.5-8B</td><td>8B</td><td>Transformers</td><td>Alpaca template.</td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-F16</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-F16</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-Q4_1</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-Q4_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-Q4_K_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-Q5_1</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-Q5_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-Q5_K_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-Q5_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>14/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_4.0bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>14/48</td><td>Undi95_ReMM-SLERP-L2-13B</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>13/48</td><td>alpindale_gemma-7b-it</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>13/48</td><td>GeorgiaTechResearchInstitute_galactica-30b-evol-instruct-70k</td><td>30B</td><td>Transformers</td><td>GALACTICA template.</td></tr>
<tr><td>13/48</td><td>gradientai_Llama-3-8B-Instruct-262k</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>13/48</td><td>gradientai_Llama-3-8B-Instruct-Gradient-1048k</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>13/48</td><td>internlm_internlm2-wqx-20b</td><td>20B</td><td>Transformers</td><td></td></tr>
<tr><td>13/48</td><td>nvidia_ChatQA-1.5-8B</td><td>8B</td><td>Transformers</td><td>NVIDIA-ChatQA template.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-F32</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-F32</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q4_0</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q5_1</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q5_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q5_K_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q5_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q6_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q8_0</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q8_0</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>13/48</td><td>turboderp_dbrx-instruct-exl2_3.75bpw</td><td>132B</td><td>ExLlamav2_HF</td><td>Without the "You are DBRX..." system prompt.</td></tr>
<tr><td>12/48</td><td>HuggingFaceH4_zephyr-7b-beta</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>12/48</td><td>ISTA-DASLab_Meta-Llama-3-8B-Instruct-AQLM-2Bit-1x16</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>12/48</td><td>llama-65b.Q5_K_M</td><td>65B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>12/48</td><td>Meta-Llama-3-70B-Instruct-IQ1_S</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>12/48</td><td>NousResearch_Llama-2-13b-chat-hf</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>12/48</td><td>Phi-3-mini-128k-instruct-IQ3_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>12/48</td><td>Phi-3-mini-128k-instruct-Q3_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>12/48</td><td>Phi-3-mini-128k-instruct-Q3_K_L</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>12/48</td><td>Phi-3-mini-128k-instruct-Q3_K_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>11/48</td><td>Meta-Llama-3-8B-Instruct-IQ2_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>11/48</td><td>Meta-Llama-3-8B-Instruct-Q2_K</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>11/48</td><td>mlabonne_phixtral-2x2_8</td><td>2x2.8B</td><td>Transformers</td><td></td></tr>
<tr><td>11/48</td><td>mlfoundations_tabula-8b</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>11/48</td><td>nyunai_nyun-c2-llama3-56B</td><td>56B</td><td>Transformers</td><td>--load-in-8bit</td></tr>
<tr><td>11/48</td><td>Phi-3-mini-128k-instruct-IQ3_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>11/48</td><td>Phi-3-mini-128k-instruct-Q3_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>11/48</td><td>Phi-3-mini-128k-instruct-Q3_K_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>11/48</td><td>Phi-3-mini-128k-instruct-Q4_1</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>11/48</td><td>Phi-3-mini-128k-instruct-Q4_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>10/48</td><td>facebook_galactica-30b</td><td>30B</td><td>Transformers</td><td></td></tr>
<tr><td>10/48</td><td>ISTA-DASLab_c4ai-command-r-v01-AQLM-2Bit-1x16</td><td>35B</td><td>Transformers</td><td></td></tr>
<tr><td>10/48</td><td>Phi-3-mini-128k-instruct-Q3_K_L</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>10/48</td><td>Phi-3-mini-128k-instruct-Q3_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>9/48</td><td>microsoft_phi-2</td><td>2.7B</td><td>Transformers</td><td></td></tr>
<tr><td>9/48</td><td>Qwen_Qwen2-1.5B-Instruct</td><td>1.5B</td><td>Transformers</td><td></td></tr>
<tr><td>9/48</td><td>TheBloke_vicuna-33B-GPTQ</td><td>33B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>8/48</td><td>gradientai_Llama-3-8B-Instruct-Gradient-1048k</td><td>8B</td><td>Transformers</td><td>Revision of 2024/05/04.</td></tr>
<tr><td>8/48</td><td>ISTA-DASLab_Meta-Llama-3-8B-Instruct-AQLM-2Bit-1x16</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>8/48</td><td>Meta-Llama-3-8B-Instruct-IQ2_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>8/48</td><td>mistralai_Mistral-7B-Instruct-v0.1</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>8/48</td><td>NousResearch_Llama-2-7b-chat-hf</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>8/48</td><td>NousResearch_Nous-Capybara-7B-V1.9</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>8/48</td><td>Phi-3-mini-128k-instruct-IQ3_XS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>8/48</td><td>Phi-3-mini-128k-instruct-IQ3_XXS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>8/48</td><td>Phi-3-mini-128k-instruct-Q3_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>7/48</td><td>GeorgiaTechResearchInstitute_galactica-30b-evol-instruct-70k</td><td>30B</td><td>Transformers</td><td>Alpaca template.</td></tr>
<tr><td>7/48</td><td>tiiuae_falcon-11B</td><td>11B</td><td>Transformers</td><td></td></tr>
<tr><td>6/48</td><td>tiiuae_falcon-40b-instruct</td><td>40B</td><td>Transformers</td><td>--load-in-8bit; falcon-180B-chat instruction template.</td></tr>
<tr><td>5/48</td><td>internlm_internlm2-chat-1_8b-sft</td><td>1.8B</td><td>Transformers</td><td></td></tr>
<tr><td>5/48</td><td>LoneStriker_deepseek-coder-33b-instruct-6.0bpw-h6-exl2</td><td>33B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>5/48</td><td>Meta-Llama-3-8B-Instruct-IQ2_XS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>5/48</td><td>NousResearch_Llama-2-13b-hf</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>5/48</td><td>Phi-3-mini-128k-instruct-Q2_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>5/48</td><td>TheBloke_Llama-2-13B-GPTQ</td><td>13B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>5/48</td><td>unsloth_llama-3-70b-bnb-4bit</td><td>70B</td><td>Transformers</td><td></td></tr>
<tr><td>4/48</td><td>internlm_internlm2-chat-1_8b</td><td>1.8B</td><td>Transformers</td><td></td></tr>
<tr><td>4/48</td><td>TheBloke_deepseek-coder-33B-instruct-AWQ</td><td>33B</td><td>AutoAWQ</td><td></td></tr>
<tr><td>4/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_3.0bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>3/48</td><td>TheBloke_Llama-2-7B-GPTQ</td><td>7B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>3/48</td><td>turboderp_dbrx-instruct-exl2_3.75bpw</td><td>132B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>2/48</td><td>facebook_galactica-6.7b</td><td>6.7B</td><td>Transformers</td><td></td></tr>
<tr><td>2/48</td><td>Meta-Llama-3-8B-Instruct-IQ2_XXS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>1/48</td><td>bartowski_CodeQwen1.5-7B-Chat-exl2_8_0</td><td>7B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>1/48</td><td>NousResearch_Llama-2-7b-hf</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>1/48</td><td>Phi-3-mini-128k-instruct-IQ2_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>1/48</td><td>Phi-3-mini-128k-instruct-Q2_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>1/48</td><td>Qwen_CodeQwen1.5-7B-Chat</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>1/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_2.5bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>0/48</td><td>EleutherAI_gpt-j-6b</td><td>6B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>EleutherAI_gpt-neo-1.3B</td><td>1.3B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>EleutherAI_gpt-neo-2.7B</td><td>2.7B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>EleutherAI_gpt-neox-20b</td><td>20B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_galactica-1.3b</td><td>1.3B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_galactica-125m</td><td>0.125B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_opt-13b</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_opt-30b</td><td>30B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_opt-6.7b</td><td>6.7B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>gpt4chan_model_float16</td><td>6B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>ISTA-DASLab_Llama-2-7b-AQLM-2Bit-1x16-hf</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>Meta-Llama-3-8B-Instruct-IQ1_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>0/48</td><td>Meta-Llama-3-8B-Instruct-IQ1_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>0/48</td><td>openai-community_gpt2</td><td>0.124B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>openai-community_gpt2-large</td><td>0.774B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>openai-community_gpt2-medium</td><td>0.355B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>openai-community_gpt2-xl</td><td>1.5B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ1_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ1_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ2_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ2_XS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ2_XXS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-Q2_K</td><td>3.8B</td><td>llamacpp_HF</td><td>Created without --imatrix.</td></tr>
<tr><td>0/48</td><td>Qwen_Qwen2-0.5B-Instruct</td><td>0.5B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>TinyLlama_TinyLlama-1.1B-Chat-v1.0</td><td>1.1B</td><td>Transformers</td><td></td></tr>
      </tbody>
    </table>
    <div class="comments">
      <h2>Updates</h2>
      <h3>2024/07/11</h3>
  <ul>
    <li><b style="color: blue">turboderp_gemma-2-27b-it-exl2_3.0bpw</b> (27B) - 26/48</li>
    <li><b style="color: blue">turboderp_gemma-2-27b-it-exl2_8.0bpw</b> (27B) - 32/48</li>
  </ul><h3>2024/07/03</h3>
  <ul>
    <li><b style="color: blue">microsoft_Phi-3-mini-4k-instruct-20240701</b> (3.8B) - 20/48</li>
    <li><b style="color: blue">microsoft_Phi-3-mini-128k-instruct-20240701</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">internlm_internlm2_5-7b-chat</b> (7B) - 26/48</li>
  </ul><h3>2024/07/02</h3>
  <ul>
    <li><b style="color: blue">UCLA-AGI_Gemma-2-9B-It-SPPO-Iter3</b> (9B) - 29/48</li>
    <li><b style="color: blue">gemma-2-9b-it-Q8_0_L</b> (9B) - 28/48</li>
    <li><b style="color: blue">gemma-2-27b-it-Q8_0_L</b> (27B) - 33/48</li>
  </ul><h3>2024/07/01</h3>
  <ul>
    <li><b style="color: blue">google_gemma-2-27b-it</b> (27B) - 33/48</li>
    <li><b style="color: blue">google_gemma-2-9b-it</b> (9B) - 29/48</li>
    <li><b style="color: blue">c4ai-command-r-plus.i1-IQ4_XS</b> (104B) - 29/48</li>
    <li><b style="color: blue">google_gemma-2-9b-it</b> (9B) - 26/48</li>
    <li><b style="color: blue">google_gemma-2-9b-it</b> (9B) - 27/48</li>
    <li><b style="color: blue">google_gemma-2-27b-it</b> (27B) - 30/48</li>
  </ul><h3>2024/06/28</h3>
  <ul>
    <li><b style="color: blue">gustavecortal_oneirogen-7B</b> (7B) - 21/48</li>
    <li><b style="color: blue">magnum-72b-v1-Q4_K_M</b> (72B) - 33/48</li>
  </ul><h3>2024/06/26</h3>
  <ul>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-abliterated-v3.5.i1-Q4_K_S</b> (70B) - 30/48</li>
    <li><b style="color: blue">UCLA-AGI_Llama-3-Instruct-8B-SPPO-Iter3</b> (8B) - 19/48</li>
    <li><b style="color: blue">ZeusLabs_L3-Aethora-15B-V2</b> (15B) - 17/48</li>
  </ul><h3>2024/06/25</h3>
  <ul>
    <li><b style="color: blue">Qwen_Qwen2-0.5B-Instruct</b> (0.5B) - 0/48</li>
    <li><b style="color: blue">Qwen_Qwen2-1.5B-Instruct</b> (1.5B) - 9/48</li>
    <li><b style="color: blue">Qwen_Qwen2-7B-Instruct</b> (7B) - 27/48</li>
    <li><b style="color: blue">turboderp_llama3-turbcat-instruct-8b</b> (8B) - 18/48</li>
    <li><b style="color: blue">mlfoundations_tabula-8b</b> (8B) - 11/48</li>
    <li><b style="color: blue">internlm_internlm2-wqx-20b</b> (20B) - 13/48</li>
    <li><b style="color: blue">nyunai_nyun-c2-llama3-56B</b> (56B) - 11/48</li>
    <li><b style="color: blue">dolphin-2.9.3-Yi-1.5-34B-32k-Q8_0</b> (34B) - 33/48</li>
    <li><b style="color: blue">Llama3-70B-ShiningValiant2.i1-Q4_K_M</b> (70B) - 30/48</li>
    <li><b style="color: blue">Qwen2-72B-Instruct-Q4_K_M</b> (72B) - 32/48</li>
  </ul><h3>2024/05/24</h3>
  <ul>
    <li><b style="color: blue">openchat_openchat-3.6-8b-20240522</b> (8B) - 17/48</li>
  </ul><h3>2024/05/23</h3>
  <ul>
    <li><b style="color: blue">CohereForAI_aya-23-35B</b> (35B) - 20/48</li>
    <li><b style="color: blue">kubernetes-bad_Mistral-7B-Instruct-v0.3</b> (7B) - 17/48</li>
  </ul><h3>2024/05/21</h3>
  <ul>
    <li><b style="color: blue">microsoft_Phi-3-medium-128k-instruct</b> (14B) - 31/48</li>
    <li><b style="color: blue">microsoft_Phi-3-medium-4k-instruct</b> (14B) - 29/48</li>
    <li><b style="color: blue">microsoft_Phi-3-vision-128k-instruct</b> (4.2B) - 21/48</li>
    <li><b style="color: blue">microsoft_Phi-3-small-8k-instruct</b> (7B) - 26/48</li>
    <li><b style="color: blue">microsoft_Phi-3-small-128k-instruct</b> (7B) - 21/48</li>
  </ul><h3>2024/05/20</h3>
  <ul>
    <li><b style="color: blue">01-ai_Yi-1.5-34B-Chat-16K</b> (34B) - 33/48</li>
  </ul><h3>2024/05/19</h3>
  <ul>
    <li><b style="color: blue">tiiuae_falcon-11B</b> (11B) - 7/48</li>
    <li><b style="color: blue">Salesforce_SFR-Iterative-DPO-LLaMA-3-8B-R</b> (8B) - 21/48</li>
    <li><b style="color: blue">Smaug-Llama-3-70B-Instruct.i1-Q4_K_S</b> (70B) - 33/48</li>
  </ul><h3>2024/05/12</h3>
  <ul>
    <li><b style="color: blue">01-ai_Yi-1.5-34B-Chat</b> (34B) - 33/48</li>
    <li><b style="color: blue">01-ai_Yi-1.5-9B-Chat</b> (9B) - 27/48</li>
    <li><b style="color: blue">01-ai_Yi-1.5-6B-Chat</b> (6B) - 21/48</li>
  </ul><h3>2024/05/10</h3>
  <ul>
    <li><b style="color: blue">Dracones_Llama-3-Lumimaid-70B-v0.1_exl2_4.5bpw</b> (70B) - 29/48</li>
  </ul><h3>2024/05/07</h3>
  <ul>
    <li><b style="color: blue">turboderp_command-r-plus-103B-exl2_3.0bpw</b> (104B) - 29/48</li>
    <li><b style="color: blue">turboderp_command-r-plus-103B-exl2_2.5bpw</b> (104B) - 22/48</li>
    <li><b style="color: blue">Qwen_CodeQwen1.5-7B-Chat</b> (7B) - 1/48</li>
    <li><b style="color: blue">bartowski_CodeQwen1.5-7B-Chat-exl2_8_0</b> (7B) - 1/48</li>
    <li><b style="color: blue">LoneStriker_Llama-3-70B-Instruct-Gradient-262k-6.0bpw-h6-exl2</b> (70B) - 24/48</li>
    <li><b style="color: blue">LoneStriker_Llama-3-70B-Instruct-Gradient-524k-6.0bpw-h6-exl2</b> (70B) - 25/48</li>
    <li><b style="color: blue">Llama3-TenyxChat-70B.i1-Q4_K_S</b> (70B) - 33/48</li>
  </ul><h3>2024/05/06</h3>
  <ul>
    <li><b style="color: blue">Llama-3-Giraffe-70B-Instruct.i1-Q4_K_S</b> (70B) - 32/48</li>
    <li><b style="color: blue">turboderp_Cat-Llama-3-70B-instruct-exl2_5.0bpw</b> (70B) - 33/48</li>
    <li><b style="color: blue">failspy_kappa-3-phi-abliterated</b> (3.8B) - 18/48</li>
    <li><b style="color: blue">turboderp_command-r-plus-103B-exl2_3.5bpw</b> (104B) - 28/48</li>
    <li><b style="color: blue">turboderp_command-r-plus-103B-exl2_4.5bpw</b> (104B) - 28/48</li>
  </ul><h3>2024/05/05</h3>
  <ul>
    <li><b style="color: blue">Platypus2-70B.i1-Q4_K_M</b> (70B) - 27/48</li>
    <li><b style="color: blue">LoneStriker_Yi-34B-Chat-8.0bpw-h8-exl2</b> (34B) - 29/48</li>
    <li><b style="color: blue">LoneStriker_dolphin-2.2-yi-34b-200k-8.0bpw-h8-exl2</b> (34B) - 26/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q2_K</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K</b> (3.8B) - 11/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K_L</b> (3.8B) - 10/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K_M</b> (3.8B) - 11/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K_S</b> (3.8B) - 8/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_0</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_1</b> (3.8B) - 11/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_K</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_K_M</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_K_S</b> (3.8B) - 11/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_0</b> (3.8B) - 15/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_1</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_K</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_K_M</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_K_S</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q6_K</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q8_0</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-F16</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-F32</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">LoneStriker_Yi-34B-200K-8.0bpw-h8-exl2</b> (34B) - 26/48</li>
    <li><b style="color: blue">microsoft_Phi-3-mini-128k-instruct</b> (3.8B) - 18/48</li>
    <li><b style="color: blue">microsoft_Phi-3-mini-128k-instruct</b> (3.8B) - 17/48</li>
    <li><b style="color: blue">Meta-Llama-3-120B-Instruct.Q4_K_M</b> (120B) - 31/48</li>
  </ul><h3>2024/05/04</h3>
  <ul>
    <li><b style="color: blue">jieliu_Storm-7B</b> (7B) - 18/48</li>
    <li><b style="color: blue">miquliz-120b-v2.0.Q4_K_M</b> (120B) - 30/48</li>
    <li><b style="color: blue">internlm_internlm2-chat-1_8b</b> (1.8B) - 4/48</li>
    <li><b style="color: blue">internlm_internlm2-chat-1_8b-sft</b> (1.8B) - 5/48</li>
    <li><b style="color: blue">internlm_internlm2-chat-20b</b> (20B) - 21/48</li>
    <li><b style="color: blue">internlm_internlm2-chat-20b-sft</b> (20B) - 19/48</li>
    <li><b style="color: blue">internlm_internlm2-chat-7b</b> (7B) - 19/48</li>
    <li><b style="color: blue">internlm_internlm2-chat-7b-sft</b> (7B) - 17/48</li>
    <li><b style="color: blue">TheProfessor-155b.i1-IQ3_XS</b> (155B) - 18/48</li>
    <li><b style="color: blue">ISTA-DASLab_c4ai-command-r-plus-AQLM-2Bit-1x16</b> (104B) - 27/48</li>
    <li><b style="color: blue">ISTA-DASLab_c4ai-command-r-v01-AQLM-2Bit-1x16</b> (35B) - 10/48</li>
    <li><b style="color: blue">ISTA-DASLab_Meta-Llama-3-70B-Instruct-AQLM-2Bit-1x16</b> (70B) - 33/48</li>
    <li><b style="color: blue">ISTA-DASLab_Meta-Llama-3-8B-Instruct-AQLM-2Bit-1x16</b> (8B) - 12/48</li>
    <li><b style="color: blue">gradientai_Llama-3-8B-Instruct-Gradient-1048k</b> (8B) - 8/48</li>
  </ul><h3>2024/05/03</h3>
  <ul>
    <li><b style="color: blue">gradientai_Llama-3-8B-Instruct-Gradient-1048k</b> (8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-F16</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-F32</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ1_M</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ1_S</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ2_M</b> (3.8B) - 1/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ2_S</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ2_XS</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ2_XXS</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ3_M</b> (3.8B) - 12/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ3_S</b> (3.8B) - 11/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ3_XS</b> (3.8B) - 8/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ3_XXS</b> (3.8B) - 8/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ4_NL</b> (3.8B) - 15/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ4_XS</b> (3.8B) - 15/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q2_K</b> (3.8B) - 5/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q2_K_S</b> (3.8B) - 1/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K</b> (3.8B) - 12/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K_L</b> (3.8B) - 12/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K_M</b> (3.8B) - 12/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K_S</b> (3.8B) - 10/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_0</b> (3.8B) - 15/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_1</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_K</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_K_M</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_K_S</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_0</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_1</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_K</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_K_M</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_K_S</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q6_K</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q8_0</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_2.5bpw</b> (3.8B) - 1/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_3.0bpw</b> (3.8B) - 4/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_4.0bpw</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_5.0bpw</b> (3.8B) - 17/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_6.0bpw</b> (3.8B) - 17/48</li>
    <li><b style="color: blue">hjhj3168_Llama-3-8b-Orthogonalized-exl2</b> (8B) - 15/48</li>
    <li><b style="color: blue">ai21labs_Jamba-v0.1</b> (52B) - 19/48</li>
    <li><b style="color: blue">Llama3-ChatQA-1.5-70B.Q4_K_M</b> (70B) - 29/48</li>
    <li><b style="color: blue">Llama3-ChatQA-1.5-70B.Q4_K_M</b> (70B) - 27/48</li>
    <li><b style="color: blue">nvidia_ChatQA-1.5-8B</b> (8B) - 13/48</li>
    <li><b style="color: blue">nvidia_ChatQA-1.5-8B</b> (8B) - 14/48</li>
    <li><b style="color: blue">NousResearch_Hermes-2-Pro-Llama-3-8B</b> (8B) - 15/48</li>
    <li><b style="color: blue">TheBloke_deepseek-coder-33B-instruct-AWQ</b> (33B) - 4/48</li>
    <li><b style="color: blue">LoneStriker_deepseek-coder-33b-instruct-6.0bpw-h6-exl2</b> (33B) - 5/48</li>
  </ul><h3>2024/04/28</h3>
  <ul>
    <li><b style="color: blue">facebook_galactica-1.3b</b> (1.3B) - 0/48</li>
    <li><b style="color: blue">facebook_opt-6.7b</b> (6.7B) - 0/48</li>
    <li><b style="color: blue">facebook_opt-13b</b> (13B) - 0/48</li>
    <li><b style="color: blue">facebook_opt-30b</b> (30B) - 0/48</li>
    <li><b style="color: blue">GeorgiaTechResearchInstitute_galactica-30b-evol-instruct-70k</b> (30B) - 13/48</li>
    <li><b style="color: blue">GeorgiaTechResearchInstitute_galactica-30b-evol-instruct-70k</b> (30B) - 7/48</li>
    <li><b style="color: blue">EleutherAI_gpt-j-6b</b> (6B) - 0/48</li>
    <li><b style="color: blue">EleutherAI_gpt-neo-2.7B</b> (2.7B) - 0/48</li>
    <li><b style="color: blue">EleutherAI_gpt-neo-1.3B</b> (1.3B) - 0/48</li>
    <li><b style="color: blue">openai-community_gpt2</b> (0.124B) - 0/48</li>
    <li><b style="color: blue">openai-community_gpt2-medium</b> (0.355B) - 0/48</li>
    <li><b style="color: blue">openai-community_gpt2-large</b> (0.774B) - 0/48</li>
    <li><b style="color: blue">openai-community_gpt2-xl</b> (1.5B) - 0/48</li>
    <li><b style="color: blue">EleutherAI_gpt-neox-20b</b> (20B) - 0/48</li>
  </ul><h3>2024/04/27</h3>
  <ul>
    <li><b style="color: blue">Undi95_Meta-Llama-3-70B-Instruct-hf</b> (70B) - 33/48</li>
    <li><b style="color: blue">LoneStriker_dolphin-2.9-llama3-70b-6.0bpw-h6-exl2</b> (70B) - 33/48</li>
    <li><b style="color: blue">LoneStriker_OpenBioLLM-Llama3-70B-6.0bpw-h6-exl2</b> (70B) - 34/48</li>
    <li><b style="color: blue">BAAI_Bunny-Llama-3-8B-V</b> (8B) - 20/48</li>
    <li><b style="color: blue">mzbac_llama-3-8B-Instruct-function-calling</b> (8B) - 17/48</li>
  </ul><h3>2024/04/26</h3>
  <ul>
    <li><b style="color: blue">Weyaxi_Einstein-v6.1-Llama3-8B</b> (8B) - 20/48</li>
    <li><b style="color: blue">Qwen1.5-110B-Chat-Q4_K_M</b> (110B) - 29/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ2_M</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ2_S</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ2_XS</b> (70B) - 31/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ3_M</b> (70B) - 31/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ3_S</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ3_XS</b> (70B) - 33/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ3_XXS</b> (70B) - 33/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ4_NL</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ4_XS</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q2_K</b> (70B) - 31/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q3_K_L</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q3_K_M</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q3_K_S</b> (70B) - 33/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q4_K_S</b> (70B) - 34/48</li>
  </ul><h3>2024/04/25</h3>
  <ul>
    <li><b style="color: blue">34b-beta.Q8_0</b> (34B) - 29/48</li>
    <li><b style="color: blue">platypus-yi-34b.Q8_0</b> (34B) - 34/48</li>
    <li><b style="color: blue">CausalLM-RP-34B.q8_0</b> (34B) - 26/48</li>
    <li><b style="color: blue">MoMo-72B-lora-1.8.6-DPO-Q4_K_M</b> (72B) - 22/48</li>
    <li><b style="color: blue">ggml-alpaca-dragon-72b-v1-q4_k_m</b> (72B) - 17/48</li>
    <li><b style="color: blue">cloudyu_Phoenix_DPO_60B</b> (60B) - 31/48</li>
    <li><b style="color: blue">TheBloke_Helion-4x34B-GPTQ</b> (4x34B) - 27/48</li>
    <li><b style="color: blue">bhenrym14_airoboros-3_1-yi-34b-200k</b> (34B) - 23/48</li>
    <li><b style="color: blue">gradientai_Llama-3-8B-Instruct-262k</b> (8B) - 13/48</li>
  </ul><h3>2024/04/24</h3>
  <ul>
    <li><b style="color: blue">falcon-180b-chat.Q4_K_M</b> (180B) - 30/48</li>
    <li><b style="color: blue">falcon-180b.Q4_K_M</b> (180B) - 21/48</li>
    <li><b style="color: blue">grok-1-IQ2_XS</b> (314B) - 17/48</li>
    <li><b style="color: blue">lightblue_suzume-llama-3-8B-multilingual</b> (8B) - 19/48</li>
    <li><b style="color: blue">tiiuae_falcon-40b-instruct</b> (40B) - 6/48</li>
    <li><b style="color: blue">LoneStriker_Smaug-72B-v0.1-6.0bpw-h6-exl2</b> (72B) - 28/48</li>
    <li><b style="color: blue">Rhea-72b-v0.5-Q4_K_M</b> (72B) - 30/48</li>
    <li><b style="color: blue">MultiVerse_70B.Q4_K_M</b> (70B) - 24/48</li>
    <li><b style="color: blue">Ein-72B-v0.1-full.Q4_K_M</b> (72B) - 20/48</li>
    <li><b style="color: blue">xwin-lm-70b-v0.1.Q4_K_M</b> (70B) - 23/48</li>
    <li><b style="color: blue">ISTA-DASLab_Meta-Llama-3-8B-Instruct-AQLM-2Bit-1x16</b> (8B) - 8/48</li>
    <li><b style="color: blue">zephyr-orpo-141b-A35b-v0.1.Q4_K_M</b> (141B) - 19/48</li>
  </ul><h3>2024/04/23</h3>
  <ul>
    <li><b style="color: blue">microsoft_Phi-3-mini-128k-instruct</b> (3.8B) - 19/48</li>
    <li><b style="color: blue">microsoft_Phi-3-mini-4k-instruct</b> (3.8B) - 23/48</li>
    <li><b style="color: blue">meraGPT_mera-mix-4x7B</b> (4x7B) - 22/48</li>
    <li><b style="color: blue">Orenguteng_Lexi-Llama-3-8B-Uncensored</b> (8B) - 18/48</li>
  </ul>
        <h2>About</h2>
        <p>This test consists of 48 manually written multiple-choice questions. It evaluates a combination of academic knowledge and logical reasoning.</p>
        <p>Compared to MMLU, it has the advantage of not being in any training dataset, and the disadvantage of being much smaller. Compared to lmsys chatbot arena, it is harsher on small models like Starling-LM-7B-beta that write nicely formatted replies but don't have much knowledge.</p>
        <p>The correct Jinja2 instruction template is used for each model, as autodetected by text-generation-webui from the model's metadata. For base models without a template, Alpaca is used. The questions are evaluated using the /v1/internal/logits endpoint in the project's API.</p>
        <p>The questions are private.</p>
        <h2>Limitations</h2>
        <p>This benchmark does not evaluate code generation, non-English languages, role-playing, RAG, and long context understanding. The performance in those areas may have a weak or nonexistent correlation with what is being measured.</p>
    </div>
    <div class="support">
      <iframe src="https://github.com/sponsors/oobabooga/button" title="Sponsor oobabooga" height="32" width="114" style="border: 0; border-radius: 6px;"></iframe>
    </div>
  </div>
  <script>
    // Get the table and table headers
    const table = document.querySelector('table');
    const headers = table.querySelectorAll('th');
    const rows = Array.from(table.querySelectorAll('tbody tr'));
    const inputs = []; // Store all input fields

    // Create input fields for searching
    headers.forEach((header, columnIndex) => {
      const br = document.createElement('br'); // Add a line break
      header.appendChild(br);

      const input = document.createElement('input');
      input.type = 'text';
      input.placeholder = `Search ${header.textContent}`;
      header.appendChild(input);

      inputs.push(input); // Store the input field

      input.addEventListener('input', () => {
        filterRows(); // Call filterRows without arguments
      });
    });

    // Function to filter rows based on input values
    function filterRows() {
      rows.forEach((row) => {
        let isVisible = true; // Assume the row is visible

        inputs.forEach((input, columnIndex) => {
          const searchValue = input.value;
          if (searchValue !== '') { // If the input field has a value
            const regex = new RegExp(searchValue, 'i'); // Create a regex with the search value
            const cellValue = row.cells[columnIndex].textContent;

            if (!regex.test(cellValue)) { // If the cell value doesn't match the search value
              isVisible = false; // Mark the row as hidden
            }
          }
        });

        row.style.display = isVisible ? '' : 'none';
      });
    }
  </script>
</body>

</html>
