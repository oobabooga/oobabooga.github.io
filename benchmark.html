<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>oobabooga benchmark</title>
    <style>
        body {
            font-family: 'Courier New', monospace;
            margin: 0;
            padding: 20px;
            background-color: #e0e0e0;
            color: #333;
        }
        .container {
            max-width: 1320px;
            margin: auto;
            padding: 20px;
            background-color: #f0f0f0;
            border: 2px solid #aaa;
            overflow-x: scroll;
        }
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid #888;
            padding: 8px;
            text-align: left;
            color: #333;
        }
        th {
            background-color: #ccc;
        }
        .title {
            text-align: center;
            color: #333;
            font-size: 24px;
            margin-bottom: 36px;
        }
        .comments {
            margin-top: 20px;
            padding: 10px;
            background-color: #f0f0f0;
            border-top: 2px solid #aaa;
            border-bottom: 2px solid #aaa;
            margin-bottom: 30px;
        }
        .support {
            text-align: center;
            margin-top: 20px;
            font-size: 18px;
        }
        a {
            color: #0066cc; /* A nice shade of blue for the link */
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        hr {
            border: none;
        }
        .colspan-5 {
            border-left: transparent;
            border-right: transparent;
        }
        th input[type="text"] {
            width: 100%;
            box-sizing: border-box;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="title">oobabooga benchmark</h1>
        <table>
            <thead>
                <tr>
                    <th>Score</th>
                    <th>Model</th>
                    <th>Size</th>
                    <th>Loader</th>
                    <th>Additional info</th>
                </tr>
            </thead>
            <tbody>
            <tr><td>34/48</td><td>platypus-yi-34b.Q8_0</td><td>34B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>34/48</td><td>Meta-Llama-3-70B-Instruct-Q4_K_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>34/48</td><td>LoneStriker_OpenBioLLM-Llama3-70B-6.0bpw-h6-exl2</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>33/48</td><td>turboderp_Llama-3-70B-Instruct-exl2_6.0bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>33/48</td><td>turboderp_Llama-3-70B-Instruct-exl2_5.0bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>33/48</td><td>Undi95_Meta-Llama-3-70B-Instruct-hf</td><td>70B</td><td>Transformers</td><td>--load-in-4bit</td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct.Q8_0</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct-Q3_K_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct-IQ3_XXS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>33/48</td><td>Meta-Llama-3-70B-Instruct-IQ3_XS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>33/48</td><td>LoneStriker_dolphin-2.9-llama3-70b-6.0bpw-h6-exl2</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-Q3_K_M</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-Q3_K_L</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ4_XS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ4_NL</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ3_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_S</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>32/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_M</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>31/48</td><td>oobabooga_miqu-1-70b-sf-EXL2-6.000b</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>31/48</td><td>miqu-1-70b.q5_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>31/48</td><td>miqu-1-70b.q4_k_m</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>31/48</td><td>cloudyu_Phoenix_DPO_60B</td><td>60B</td><td>Transformers</td><td>--load-in-8bit</td></tr>
<tr><td>31/48</td><td>Meta-Llama-3-70B-Instruct-Q2_K</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>31/48</td><td>Meta-Llama-3-70B-Instruct-IQ3_M</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>31/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_XS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/blob/main/Meta-Llama-3-70B-Instruct-IQ2_XS.gguf">[link]</a></td></tr>
<tr><td>31/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_XS</td><td>70B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/">[link]</a></td></tr>
<tr><td>30/48</td><td>turboderp_Mixtral-8x22B-Instruct-v0.1-exl2_4.0bpw</td><td>8x22B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>30/48</td><td>qwen1_5-72b-chat-q4_k_m</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>30/48</td><td>falcon-180b-chat.Q4_K_M</td><td>180B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>30/48</td><td>Senku-70B-Full-Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>30/48</td><td>Rhea-72b-v0.5-Q4_K_M</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>30/48</td><td>Dracones_WizardLM-2-8x22B_exl2_4.0bpw</td><td>8x22B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>29/48</td><td>turboderp_Llama-3-70B-exl2_5.0bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>29/48</td><td>daybreak-miqu-1-70b-v1.0-q5_k_m</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>29/48</td><td>command-r-plus-104b-iq4_xs</td><td>104B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>29/48</td><td>bartowski_Qwen1.5-32B-Chat-exl2_5_0</td><td>32B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>29/48</td><td>Qwen1.5-110B-Chat-Q4_K_M</td><td>110B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/LoneStriker/Qwen1.5-110B-Chat-GGUF/">[link]</a></td></tr>
<tr><td>29/48</td><td>Llama3-ChatQA-1.5-70B.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td>Alpaca template.</td></tr>
<tr><td>29/48</td><td>34b-beta.Q8_0</td><td>34B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>28/48</td><td>dolphin-2.7-mixtral-8x7b.Q8_0</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>28/48</td><td>command-r-plus-Q4_K_M</td><td>104B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>28/48</td><td>LoneStriker_Smaug-72B-v0.1-6.0bpw-h6-exl2</td><td>72B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>27/48</td><td>turboderp_command-r-plus-103B-exl2_3.25bpw</td><td>104B</td><td>ExLlamav2_HF</td><td>--cache_8bit</td></tr>
<tr><td>27/48</td><td>mixtral-8x7b-instruct-v0.1.Q8_0</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>27/48</td><td>miqu-1-70b.q2_K</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>27/48</td><td>TheBloke_Helion-4x34B-GPTQ</td><td>4x34B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>27/48</td><td>Midnight-Miqu-70B-v1.0.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>27/48</td><td>Llama3-ChatQA-1.5-70B.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td>NVIDIA-ChatQA template.</td></tr>
<tr><td>26/48</td><td>nous-hermes-2-mixtral-8x7b-dpo.Q8_0</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>26/48</td><td>lzlv_70b_fp16_hf.Q5_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>26/48</td><td>Qwen_Qwen1.5-14B-Chat</td><td>14B</td><td>Transformers</td><td></td></tr>
<tr><td>26/48</td><td>Mixtral-8x22B-Instruct-v0.1.Q4_K_M</td><td>8x22B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>26/48</td><td>Meta-Llama-3-70B-Instruct-IQ2_XXS</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>26/48</td><td>CausalLM-RP-34B.q8_0</td><td>34B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>25/48</td><td>turboderp_Llama-3-70B-Instruct-exl2_2.4bpw</td><td>70B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>25/48</td><td>goliath-120b.Q4_K_M</td><td>120B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>25/48</td><td>NousResearch_Nous-Hermes-2-SOLAR-10.7B</td><td>10.7B</td><td>Transformers</td><td></td></tr>
<tr><td>24/48</td><td>upstage_SOLAR-10.7B-Instruct-v1.0</td><td>10.7B</td><td>Transformers</td><td></td></tr>
<tr><td>24/48</td><td>maid-yuzu-v8-alter.Q8_0</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>24/48</td><td>MultiVerse_70B.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>23/48</td><td>xwin-lm-70b-v0.1.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>23/48</td><td>microsoft_Phi-3-mini-4k-instruct</td><td>3.8B</td><td>Transformers</td><td></td></tr>
<tr><td>23/48</td><td>bhenrym14_airoboros-3_1-yi-34b-200k</td><td>34B</td><td>Transformers</td><td>--load-in-8bit</td></tr>
<tr><td>22/48</td><td>wizardlm-70b-v1.0.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>22/48</td><td>turboderp_command-r-v01-35B-exl2_6.0bpw</td><td>35B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>22/48</td><td>tulu-2-dpo-70b.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>22/48</td><td>meraGPT_mera-mix-4x7B</td><td>4x7B</td><td>Transformers</td><td></td></tr>
<tr><td>22/48</td><td>liuhaotian_llava-v1.5-13b</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>22/48</td><td>Qwen_Qwen1.5-7B-Chat</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>22/48</td><td>MoMo-72B-lora-1.8.6-DPO-Q4_K_M</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>22/48</td><td>Meta-Llama-3-8B-Instruct-Q4_K_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>21/48</td><td>falcon-180b.Q4_K_M</td><td>180B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>21/48</td><td>c4ai-command-r-v01-Q8_0</td><td>35B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>21/48</td><td>Undi95_Meta-Llama-3-8B-Instruct-hf</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>21/48</td><td>NurtureAI_Meta-Llama-3-8B-Instruct-64k</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>21/48</td><td>Meta-Llama-3-8B-Instruct-fp16</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>21/48</td><td>Meta-Llama-3-8B-Instruct-Q8_0</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>20/48</td><td>openchat_openchat_3.5</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>20/48</td><td>llama-2-70b-chat.Q4_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>20/48</td><td>Weyaxi_Einstein-v6.1-Llama3-8B</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>20/48</td><td>TheBloke_llava-v1.5-13B-GPTQ</td><td>13B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>20/48</td><td>Meta-Llama-3-8B-Instruct-Q6_K</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>20/48</td><td>Ein-72B-v0.1-full.Q4_K_M</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>20/48</td><td>BAAI_Bunny-Llama-3-8B-V</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>zephyr-orpo-141b-A35b-v0.1.Q4_K_M</td><td>141B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>mistral-7b-instruct-v0.2.Q4_K_S</td><td>7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>microsoft_Phi-3-mini-128k-instruct</td><td>3.8B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>llama-2-70b.Q5_K_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>lightblue_suzume-llama-3-8B-multilingual</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>ai21labs_Jamba-v0.1</td><td>52B</td><td>Transformers</td><td>--load-in-4bit</td></tr>
<tr><td>19/48</td><td>NousResearch_Hermes-2-Pro-Mistral-7B</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>Nexusflow_Starling-LM-7B-beta</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-Q5_K_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-Q5_K_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-Q4_K_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-IQ4_XS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-IQ4_NL</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>19/48</td><td>Meta-Llama-3-8B-Instruct-IQ3_S</td><td>8B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/blob/main/Meta-Llama-3-8B-Instruct-IQ3_S.gguf">[link]</a></td></tr>
<tr><td>18/48</td><td>mistralai_Mistral-7B-Instruct-v0.2</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>18/48</td><td>Qwen_Qwen1.5-MoE-A2.7B-Chat</td><td>14.3B</td><td>Transformers</td><td></td></tr>
<tr><td>18/48</td><td>Orenguteng_Lexi-Llama-3-8B-Uncensored</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>18/48</td><td>Meta-Llama-3-8B-Instruct-Q3_K_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>18/48</td><td>Meta-Llama-3-8B-Instruct-Q3_K_L</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>18/48</td><td>Meta-Llama-3-70B-Instruct-IQ1_M</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>18/48</td><td>LoneStriker_Nous-Capybara-34B-4.65bpw-h6-exl2</td><td>34B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>17/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_6.0bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>17/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_5.0bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>17/48</td><td>mzbac_llama-3-8B-Instruct-function-calling</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>17/48</td><td>grok-1-IQ2_XS</td><td>314B</td><td>llamacpp_HF</td><td><a href="https://huggingface.co/Arki05/Grok-1-GGUF/tree/main/IQ2_XS">[link]</a></td></tr>
<tr><td>17/48</td><td>ggml-alpaca-dragon-72b-v1-q4_k_m</td><td>72B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>17/48</td><td>amazingvince_Not-WizardLM-2-7B</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>17/48</td><td>Undi95_Toppy-M-7B</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>16/48</td><td>mixtral-8x7b-instruct-v0.1.Q2_K</td><td>8x7B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>16/48</td><td>TheBloke_Mistral-7B-Instruct-v0.2-GPTQ</td><td>7B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q6_K</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q5_0</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q4_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q4_K_M</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>16/48</td><td>Phi-3-mini-128k-instruct-Q4_K</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>16/48</td><td>Meta-Llama-3-8B-Instruct-IQ3_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>15/48</td><td>xtuner_llava-llama-3-8b-v1_1</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>15/48</td><td>hjhj3168_Llama-3-8b-Orthogonalized-exl2</td><td>8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>15/48</td><td>cognitivecomputations_dolphin-2.9-llama3-8b</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>15/48</td><td>Phi-3-mini-128k-instruct-Q4_0</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>15/48</td><td>Phi-3-mini-128k-instruct-IQ4_XS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>15/48</td><td>Phi-3-mini-128k-instruct-IQ4_NL</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>15/48</td><td>NousResearch_Hermes-2-Pro-Llama-3-8B</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>15/48</td><td>Meta-Llama-3-8B-Instruct-IQ3_XS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>15/48</td><td>CohereForAI_c4ai-command-r-v01-4bit</td><td>35B</td><td>Transformers</td><td></td></tr>
<tr><td>14/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_4.0bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>14/48</td><td>nvidia_ChatQA-1.5-8B</td><td>8B</td><td>Transformers</td><td>Alpaca template.</td></tr>
<tr><td>14/48</td><td>microsoft_Orca-2-13b</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>14/48</td><td>mattshumer_Llama-3-8B-16K</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>14/48</td><td>Undi95_ReMM-SLERP-L2-13B</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-Q5_1</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-Q4_1</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>14/48</td><td>Phi-3-mini-128k-instruct-F16</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>14/48</td><td>Meta-Llama-3-8B-Instruct-Q3_K_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>14/48</td><td>Meta-Llama-3-8B-Instruct-IQ3_XXS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>14/48</td><td>Gryphe_MythoMax-L2-13b</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>13/48</td><td>turboderp_dbrx-instruct-exl2_3.75bpw</td><td>132B</td><td>ExLlamav2_HF</td><td>Without the "You are DBRX..." system prompt.</td></tr>
<tr><td>13/48</td><td>nvidia_ChatQA-1.5-8B</td><td>8B</td><td>Transformers</td><td>NVIDIA-ChatQA template.</td></tr>
<tr><td>13/48</td><td>gradientai_Llama-3-8B-Instruct-Gradient-1048k</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>13/48</td><td>gradientai_Llama-3-8B-Instruct-262k</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>13/48</td><td>alpindale_gemma-7b-it</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q8_0</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q5_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q5_K_M</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-Q5_K</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>13/48</td><td>Phi-3-mini-128k-instruct-F32</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>13/48</td><td>GeorgiaTechResearchInstitute_galactica-30b-evol-instruct-70k</td><td>30B</td><td>Transformers</td><td>GALACTICA template.</td></tr>
<tr><td>12/48</td><td>llama-65b.Q5_K_M</td><td>65B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>12/48</td><td>Phi-3-mini-128k-instruct-Q3_K_M</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>12/48</td><td>Phi-3-mini-128k-instruct-Q3_K_L</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>12/48</td><td>Phi-3-mini-128k-instruct-Q3_K</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>12/48</td><td>Phi-3-mini-128k-instruct-IQ3_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>12/48</td><td>NousResearch_Llama-2-13b-chat-hf</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>12/48</td><td>Meta-Llama-3-70B-Instruct-IQ1_S</td><td>70B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>12/48</td><td>HuggingFaceH4_zephyr-7b-beta</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>11/48</td><td>mlabonne_phixtral-2x2_8</td><td>2x2.8B</td><td>Transformers</td><td></td></tr>
<tr><td>11/48</td><td>Phi-3-mini-128k-instruct-IQ3_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>11/48</td><td>Meta-Llama-3-8B-Instruct-Q2_K</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>11/48</td><td>Meta-Llama-3-8B-Instruct-IQ2_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>10/48</td><td>facebook_galactica-30b</td><td>30B</td><td>Transformers</td><td></td></tr>
<tr><td>10/48</td><td>Phi-3-mini-128k-instruct-Q3_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>9/48</td><td>microsoft_phi-2</td><td>2.7B</td><td>Transformers</td><td></td></tr>
<tr><td>9/48</td><td>TheBloke_vicuna-33B-GPTQ</td><td>33B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>8/48</td><td>mistralai_Mistral-7B-Instruct-v0.1</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>8/48</td><td>Phi-3-mini-128k-instruct-IQ3_XXS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>8/48</td><td>Phi-3-mini-128k-instruct-IQ3_XS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>8/48</td><td>NousResearch_Nous-Capybara-7B-V1.9</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>8/48</td><td>NousResearch_Llama-2-7b-chat-hf</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>8/48</td><td>Meta-Llama-3-8B-Instruct-IQ2_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>8/48</td><td>ISTA-DASLab_Meta-Llama-3-8B-Instruct-AQLM-2Bit-1x16</td><td>8B</td><td>Transformers</td><td></td></tr>
<tr><td>7/48</td><td>GeorgiaTechResearchInstitute_galactica-30b-evol-instruct-70k</td><td>30B</td><td>Transformers</td><td>Alpaca template.</td></tr>
<tr><td>6/48</td><td>tiiuae_falcon-40b-instruct</td><td>40B</td><td>Transformers</td><td>--load-in-8bit; falcon-180B-chat instruction template.</td></tr>
<tr><td>5/48</td><td>unsloth_llama-3-70b-bnb-4bit</td><td>70B</td><td>Transformers</td><td></td></tr>
<tr><td>5/48</td><td>TheBloke_Llama-2-13B-GPTQ</td><td>13B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>5/48</td><td>Phi-3-mini-128k-instruct-Q2_K</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>5/48</td><td>NousResearch_Llama-2-13b-hf</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>5/48</td><td>Meta-Llama-3-8B-Instruct-IQ2_XS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>4/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_3.0bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>3/48</td><td>turboderp_dbrx-instruct-exl2_3.75bpw</td><td>132B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>3/48</td><td>TheBloke_Llama-2-7B-GPTQ</td><td>7B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>2/48</td><td>facebook_galactica-6.7b</td><td>6.7B</td><td>Transformers</td><td></td></tr>
<tr><td>2/48</td><td>Meta-Llama-3-8B-Instruct-IQ2_XXS</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>1/48</td><td>turboderp_Phi-3-mini-128k-instruct-exl2_2.5bpw</td><td>3.8B</td><td>ExLlamav2_HF</td><td></td></tr>
<tr><td>1/48</td><td>Phi-3-mini-128k-instruct-Q2_K_S</td><td>3.8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>1/48</td><td>Phi-3-mini-128k-instruct-IQ2_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>1/48</td><td>NousResearch_Llama-2-7b-hf</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>openai-community_gpt2-xl</td><td>1.5B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>openai-community_gpt2-medium</td><td>0.355B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>openai-community_gpt2-large</td><td>0.774B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>openai-community_gpt2</td><td>0.124B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>gpt4chan_model_float16</td><td>6B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_opt-6.7b</td><td>6.7B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_opt-30b</td><td>30B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_opt-13b</td><td>13B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_galactica-125m</td><td>0.125B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>facebook_galactica-1.3b</td><td>1.3B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>TinyLlama_TinyLlama-1.1B-Chat-v1.0</td><td>1.1B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ2_XXS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ2_XS</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ2_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ1_S</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Phi-3-mini-128k-instruct-IQ1_M</td><td>3.8B</td><td>llamacpp_HF</td><td>Created with groups_merged.txt for calibration.</td></tr>
<tr><td>0/48</td><td>Meta-Llama-3-8B-Instruct-IQ1_S</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>0/48</td><td>Meta-Llama-3-8B-Instruct-IQ1_M</td><td>8B</td><td>llamacpp_HF</td><td></td></tr>
<tr><td>0/48</td><td>ISTA-DASLab_Llama-2-7b-AQLM-2Bit-1x16-hf</td><td>7B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>EleutherAI_gpt-neox-20b</td><td>20B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>EleutherAI_gpt-neo-2.7B</td><td>2.7B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>EleutherAI_gpt-neo-1.3B</td><td>1.3B</td><td>Transformers</td><td></td></tr>
<tr><td>0/48</td><td>EleutherAI_gpt-j-6b</td><td>6B</td><td>Transformers</td><td></td></tr>
            </tbody>
        </table>
        <div class="comments">
            <h2>Updates</h2>
            <h3>2024/05/03</h3>
  <ul>
    <li><b style="color: blue">gradientai_Llama-3-8B-Instruct-Gradient-1048k</b> (8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-F16</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-F32</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ1_M</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ1_S</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ2_M</b> (3.8B) - 1/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ2_S</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ2_XS</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ2_XXS</b> (3.8B) - 0/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ3_M</b> (3.8B) - 12/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ3_S</b> (3.8B) - 11/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ3_XS</b> (3.8B) - 8/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ3_XXS</b> (3.8B) - 8/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ4_NL</b> (3.8B) - 15/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-IQ4_XS</b> (3.8B) - 15/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q2_K</b> (3.8B) - 5/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q2_K_S</b> (3.8B) - 1/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K</b> (3.8B) - 12/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K_L</b> (3.8B) - 12/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K_M</b> (3.8B) - 12/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q3_K_S</b> (3.8B) - 10/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_0</b> (3.8B) - 15/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_1</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_K</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_K_M</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q4_K_S</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_0</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_1</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_K</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_K_M</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q5_K_S</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q6_K</b> (3.8B) - 16/48</li>
    <li><b style="color: blue">Phi-3-mini-128k-instruct-Q8_0</b> (3.8B) - 13/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_2.5bpw</b> (3.8B) - 1/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_3.0bpw</b> (3.8B) - 4/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_4.0bpw</b> (3.8B) - 14/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_5.0bpw</b> (3.8B) - 17/48</li>
    <li><b style="color: blue">turboderp_Phi-3-mini-128k-instruct-exl2_6.0bpw</b> (3.8B) - 17/48</li>
    <li><b style="color: blue">hjhj3168_Llama-3-8b-Orthogonalized-exl2</b> (8B) - 15/48</li>
    <li><b style="color: blue">ai21labs_Jamba-v0.1</b> (52B) - 19/48</li>
    <li><b style="color: blue">Llama3-ChatQA-1.5-70B.Q4_K_M</b> (70B) - 29/48</li>
    <li><b style="color: blue">Llama3-ChatQA-1.5-70B.Q4_K_M</b> (70B) - 27/48</li>
    <li><b style="color: blue">nvidia_ChatQA-1.5-8B</b> (8B) - 13/48</li>
    <li><b style="color: blue">nvidia_ChatQA-1.5-8B</b> (8B) - 14/48</li>
    <li><b style="color: blue">NousResearch_Hermes-2-Pro-Llama-3-8B</b> (8B) - 15/48</li>
  </ul><h3>2024/04/28</h3>
  <ul>
    <li><b style="color: blue">facebook_galactica-1.3b</b> (1.3B) - 0/48</li>
    <li><b style="color: blue">facebook_opt-6.7b</b> (6.7B) - 0/48</li>
    <li><b style="color: blue">facebook_opt-13b</b> (13B) - 0/48</li>
    <li><b style="color: blue">facebook_opt-30b</b> (30B) - 0/48</li>
    <li><b style="color: blue">GeorgiaTechResearchInstitute_galactica-30b-evol-instruct-70k</b> (30B) - 13/48</li>
    <li><b style="color: blue">GeorgiaTechResearchInstitute_galactica-30b-evol-instruct-70k</b> (30B) - 7/48</li>
    <li><b style="color: blue">EleutherAI_gpt-j-6b</b> (6B) - 0/48</li>
    <li><b style="color: blue">EleutherAI_gpt-neo-2.7B</b> (2.7B) - 0/48</li>
    <li><b style="color: blue">EleutherAI_gpt-neo-1.3B</b> (1.3B) - 0/48</li>
    <li><b style="color: blue">openai-community_gpt2</b> (0.124B) - 0/48</li>
    <li><b style="color: blue">openai-community_gpt2-medium</b> (0.355B) - 0/48</li>
    <li><b style="color: blue">openai-community_gpt2-large</b> (0.774B) - 0/48</li>
    <li><b style="color: blue">openai-community_gpt2-xl</b> (1.5B) - 0/48</li>
    <li><b style="color: blue">EleutherAI_gpt-neox-20b</b> (20B) - 0/48</li>
  </ul><h3>2024/04/27</h3>
  <ul>
    <li><b style="color: blue">Undi95_Meta-Llama-3-70B-Instruct-hf</b> (70B) - 33/48</li>
    <li><b style="color: blue">LoneStriker_dolphin-2.9-llama3-70b-6.0bpw-h6-exl2</b> (70B) - 33/48</li>
    <li><b style="color: blue">LoneStriker_OpenBioLLM-Llama3-70B-6.0bpw-h6-exl2</b> (70B) - 34/48</li>
    <li><b style="color: blue">BAAI_Bunny-Llama-3-8B-V</b> (8B) - 20/48</li>
    <li><b style="color: blue">mzbac_llama-3-8B-Instruct-function-calling</b> (8B) - 17/48</li>
  </ul><h3>2024/04/26</h3>
  <ul>
    <li><b style="color: blue">Weyaxi_Einstein-v6.1-Llama3-8B</b> (8B) - 20/48</li>
    <li><b style="color: blue">Qwen1.5-110B-Chat-Q4_K_M</b> (110B) - 29/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ2_M</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ2_S</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ2_XS</b> (70B) - 31/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ3_M</b> (70B) - 31/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ3_S</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ3_XS</b> (70B) - 33/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ3_XXS</b> (70B) - 33/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ4_NL</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-IQ4_XS</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q2_K</b> (70B) - 31/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q3_K_L</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q3_K_M</b> (70B) - 32/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q3_K_S</b> (70B) - 33/48</li>
    <li><b style="color: blue">Meta-Llama-3-70B-Instruct-Q4_K_S</b> (70B) - 34/48</li>
  </ul><h3>2024/04/25</h3>
  <ul>
    <li><b style="color: blue">34b-beta.Q8_0</b> (34B) - 29/48</li>
    <li><b style="color: blue">platypus-yi-34b.Q8_0</b> (34B) - 34/48</li>
    <li><b style="color: blue">CausalLM-RP-34B.q8_0</b> (34B) - 26/48</li>
    <li><b style="color: blue">MoMo-72B-lora-1.8.6-DPO-Q4_K_M</b> (72B) - 22/48</li>
    <li><b style="color: blue">ggml-alpaca-dragon-72b-v1-q4_k_m</b> (72B) - 17/48</li>
    <li><b style="color: blue">cloudyu_Phoenix_DPO_60B</b> (60B) - 31/48</li>
    <li><b style="color: blue">TheBloke_Helion-4x34B-GPTQ</b> (4x34B) - 27/48</li>
    <li><b style="color: blue">bhenrym14_airoboros-3_1-yi-34b-200k</b> (34B) - 23/48</li>
    <li><b style="color: blue">gradientai_Llama-3-8B-Instruct-262k</b> (8B) - 13/48</li>
  </ul><h3>2024/04/24</h3>
  <ul>
    <li><b style="color: blue">falcon-180b-chat.Q4_K_M</b> (180B) - 30/48</li>
    <li><b style="color: blue">falcon-180b.Q4_K_M</b> (180B) - 21/48</li>
    <li><b style="color: blue">grok-1-IQ2_XS</b> (314B) - 17/48</li>
    <li><b style="color: blue">lightblue_suzume-llama-3-8B-multilingual</b> (8B) - 19/48</li>
    <li><b style="color: blue">tiiuae_falcon-40b-instruct</b> (40B) - 6/48</li>
    <li><b style="color: blue">LoneStriker_Smaug-72B-v0.1-6.0bpw-h6-exl2</b> (72B) - 28/48</li>
    <li><b style="color: blue">Rhea-72b-v0.5-Q4_K_M</b> (72B) - 30/48</li>
    <li><b style="color: blue">MultiVerse_70B.Q4_K_M</b> (70B) - 24/48</li>
    <li><b style="color: blue">Ein-72B-v0.1-full.Q4_K_M</b> (72B) - 20/48</li>
    <li><b style="color: blue">xwin-lm-70b-v0.1.Q4_K_M</b> (70B) - 23/48</li>
    <li><b style="color: blue">ISTA-DASLab_Meta-Llama-3-8B-Instruct-AQLM-2Bit-1x16</b> (8B) - 8/48</li>
    <li><b style="color: blue">zephyr-orpo-141b-A35b-v0.1.Q4_K_M</b> (141B) - 19/48</li>
  </ul><h3>2024/04/23</h3>
  <ul>
    <li><b style="color: blue">microsoft_Phi-3-mini-128k-instruct</b> (3.8B) - 19/48</li>
    <li><b style="color: blue">microsoft_Phi-3-mini-4k-instruct</b> (3.8B) - 23/48</li>
    <li><b style="color: blue">meraGPT_mera-mix-4x7B</b> (4x7B) - 22/48</li>
    <li><b style="color: blue">Orenguteng_Lexi-Llama-3-8B-Uncensored</b> (8B) - 18/48</li>
  </ul>
            <h2>About</h2>
            <p>This test consists of 48 manually written multiple-choice questions. It evaluates a combination of academic knowledge and logical reasoning.</p>
            <p>Compared to MMLU, it has the advantage of not being in any training dataset, and the disadvantage of being much smaller. Compared to lmsys chatbot arena, it is harsher on small models like Starling-LM-7B-beta that write nicely formatted replies but don't have much knowledge.</p>
            <p>The correct Jinja2 instruction template is used for each model, as autodetected by text-generation-webui from the model's metadata. For base models without a template, Alpaca is used. The questions are evaluated using the /v1/internal/logits endpoint in the project's API.</p>
            <p>The questions are private.</p>
            <h2>Limitations</h2>
            <p>This benchmark does not evaluate code generation, non-English languages, role-playing, RAG, and long context understanding. The performance in those areas may have a weak or nonexistent correlation with what is being measured.</p>
        </div>
        <div class="support">
            <iframe src="https://github.com/sponsors/oobabooga/button" title="Sponsor oobabooga" height="32" width="114" style="border: 0; border-radius: 6px;"></iframe>
        </div>
    </div>
    <script>
        // Get the table and table headers
        const table = document.querySelector('table');
        const headers = table.querySelectorAll('th');
        const rows = Array.from(table.querySelectorAll('tbody tr'));
        const inputs = []; // Store all input fields

        // Create input fields for searching
        headers.forEach((header, columnIndex) => {
          const br = document.createElement('br'); // Add a line break
          header.appendChild(br);

          const input = document.createElement('input');
          input.type = 'text';
          input.placeholder = `Search ${header.textContent}`;
          header.appendChild(input);

          inputs.push(input); // Store the input field

          input.addEventListener('input', () => {
            filterRows(); // Call filterRows without arguments
          });
        });

        // Function to filter rows based on input values
        function filterRows() {
          rows.forEach((row) => {
            let isVisible = true; // Assume the row is visible

            inputs.forEach((input, columnIndex) => {
              const searchValue = input.value;
              if (searchValue!== '') { // If the input field has a value
                const regex = new RegExp(searchValue, 'i'); // Create a regex with the search value
                const cellValue = row.cells[columnIndex].textContent;

                if (!regex.test(cellValue)) { // If the cell value doesn't match the search value
                  isVisible = false; // Mark the row as hidden
                }
              }
            });

            row.style.display = isVisible? '' : 'none';
          });
        }
    </script>
</body>
</html>


